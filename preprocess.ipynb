{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import array_remove\n",
    "import wordcloud\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Exploratory_Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config(\"spark.executor.cores\", '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config('spark.driver.memory', '8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format('csv'). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(\"C:/Users/Eri/Documents/PSTAT 135/model_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: string (nullable = true)\n",
      " |-- smell: string (nullable = true)\n",
      " |-- taste: string (nullable = true)\n",
      " |-- feel: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----+-----+-----+----+-------+-----+------------+\n",
      "|_c0|                text|look|smell|taste|feel|overall|score|       style|\n",
      "+---+--------------------+----+-----+-----+----+-------+-----+------------+\n",
      "|  0|   Beautiful, cry...|4.75|  4.0| 4.25|4.25|   4.25| 4.22|American IPA|\n",
      "|  1|   Poured a bit l...|3.75| 3.75| 3.75|3.75|   3.75| 3.75|American IPA|\n",
      "|  2|   355ml can. Bri...|4.25|  4.0|  4.0|4.25|    4.0| 4.04|American IPA|\n",
      "|  3|   Quite balanced...|4.25|  4.5| 4.25| 4.5|   4.25| 4.34|American IPA|\n",
      "|  4|   Can: Poured a ...|3.75| 3.75| 3.75|3.75|   3.75| 3.75|American IPA|\n",
      "+---+--------------------+----+-----+-----+----+-------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, text='\\xa0\\xa0 Beautiful, crystal clear pour with a nice head. Good retention, awesome lace. Pleasant citrus aroma, but not as powerful as some. Real good flavour here, lots of late hops, with a good bitterness and a light hop acidity. Thanks Yardsale! \\xa0', look='4.75', smell='4.0', taste='4.25', feel='4.25', overall='4.25', score='4.22', style='American IPA'),\n",
       " Row(_c0=1, text='\\xa0\\xa0 Poured a bit lively and had to wait for it to settle very nice lacing. Slightly hazy golden straw. Floral notes maybe a hint of citrus. Quite smooth on the palate a touch bitter and definitely a pungent finish as advertised. Somewhat of a dry finish and something about the lingering taste is off. The mouth coating is a touch creamy. \\xa0', look='3.75', smell='3.75', taste='3.75', feel='3.75', overall='3.75', score='3.75', style='American IPA'),\n",
       " Row(_c0=2, text='\\xa0\\xa0 355ml can. Bright copper with a dense foamy head that dissipates slowly leaving thin lacing. Pine, lemon, lime on the nose. Forceful bitterness upfront with blended citrus flavours dominating. Medium body. Very nice. \\xa0', look='4.25', smell='4.0', taste='4.0', feel='4.25', overall='4.0', score='4.04', style='American IPA'),\n",
       " Row(_c0=3, text='\\xa0\\xa0 Quite balanced and distinct IPA of a West Coast style IPA from this small prairie city brewery. Packs a punch at 7abv but the bite is layered by pine and citrus aroma and taste, but a nice malt finish and stands up to many west coast IPAs. Nice start for Black Bridge. \\xa0', look='4.25', smell='4.5', taste='4.25', feel='4.5', overall='4.25', score='4.34', style='American IPA'),\n",
       " Row(_c0=4, text='\\xa0\\xa0 Can: Poured a clear amber color ale with a large foamy head with good retention and some light lacing. Aroma of citrusy hops notes with some light dry caramel malt notes. Taste is also dominated by citrusy hops notes with medium bitter notes with some dry caramel malt notes. Body is about average with good carbonation. Slightly better than your standard IPA. \\xa0', look='3.75', smell='3.75', taste='3.75', feel='3.75', overall='3.75', score='3.75', style='American IPA')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace,col\n",
    "data1 = data.select('text', 'style')\n",
    "#for multiple regex expressions use OR |\n",
    "data1 = data1.withColumn('text', regexp_replace(col('text'), \"\\\\.|\\xa0|!|,|:\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                text|       style|\n",
      "+--------------------+------------+\n",
      "| Beautiful crysta...|American IPA|\n",
      "| Poured a bit liv...|American IPA|\n",
      "| 355ml can Bright...|American IPA|\n",
      "| Quite balanced a...|American IPA|\n",
      "| Can Poured a cle...|American IPA|\n",
      "| Can bought onlin...|American IPA|\n",
      "| Passing through ...|American IPA|\n",
      "| Yes please I've ...|American IPA|\n",
      "| A well put toget...|American IPA|\n",
      "| 355ml can the la...|American IPA|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of white space and separate each word \n",
    "data1 = data1.withColumn('text', split(data1['text'], ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.withColumn('text', array_remove('text', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words \n",
    "remover = StopWordsRemover(inputCol=\"text\", outputCol=\"filtered\")\n",
    "data2 = remover.transform(data1)\n",
    "data2 = data2.select('filtered', 'style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            filtered|       style|\n",
      "+--------------------+------------+\n",
      "|[Beautiful, cryst...|American IPA|\n",
      "|[Poured, bit, liv...|American IPA|\n",
      "|[355ml, Bright, c...|American IPA|\n",
      "|[Quite, balanced,...|American IPA|\n",
      "|[Poured, clear, a...|American IPA|\n",
      "|[bought, online, ...|American IPA|\n",
      "|[Passing, Swift, ...|American IPA|\n",
      "|[Yes, please, hop...|American IPA|\n",
      "|[well, put, toget...|American IPA|\n",
      "|[355ml, latest, n...|American IPA|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               style|count|\n",
      "+--------------------+-----+\n",
      "| too. Taste (4/5)...|    1|\n",
      "|       balanced malt|    1|\n",
      "| leaving a very nice|    1|\n",
      "| but not sharp or...|    1|\n",
      "| could use a litt...|    1|\n",
      "| smooth and full ...|    1|\n",
      "| letting the hop ...|    1|\n",
      "| citrus and pine ...|    1|\n",
      "| it would be easy...|    1|\n",
      "|           via BIF10|    1|\n",
      "| I'd give it a \"\"...|    1|\n",
      "| appleskin. Light...|    1|\n",
      "| intense bitterne...|    1|\n",
      "| IPA-style aftert...|    1|\n",
      "|                4.13|   11|\n",
      "| and almost undri...|    1|\n",
      "| lingering grapef...|    1|\n",
      "|                 1.0|   13|\n",
      "| the date was rub...|    1|\n",
      "| smoothed by the ...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#what is happening here ???\n",
    "data2.groupBy('style').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF notes from lecture \n",
    "from pyspark.mllib.feature import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec()\n",
    "model = word2vec.fit(inp)\n",
    "\n",
    "synonyms = model.findSynonyms('china', 40)\n",
    "\n",
    "for word, cosine_distance in synonyms:\n",
    "    print(\"{}: {}\".format(word, cosine_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-6fa826edbe5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageColorGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_font_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcloud\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m         \"\"\"\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \"\"\"\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mr\"\\w[\\w']+\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;31m# remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#some code about wordclouds \n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "wordcloud = WordCloud(max_font_size=40).generate(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
