{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "## I. Setting Up Environment\n",
    "1. Setting up Spark Session and Loading Data\n",
    "\n",
    "## II. Preprocessing\n",
    "2. Non-empty reviews\n",
    "\n",
    "3. Selecting 4 styles of beer to classify\n",
    "\n",
    "4. Cleaning numeric fields\n",
    "\n",
    "## III. Exploratory Analysis and Vizualizations\n",
    "5. Summary statistics for each style of beer and for entire dataset\n",
    "\n",
    "## IV. Modeling\n",
    "6. Creating Pipelines and Cross Validators\n",
    "\n",
    "7. Baseline Model for Entire Dataset (Unbalanced Classes)\n",
    "\n",
    "    7.1 CV TF-IDF Parameters\n",
    "    \n",
    "8. Baseline Model for Sampled Dataset (Balanced Classes)\n",
    "\n",
    "    8.1 CV TF-IDF Parameters\n",
    "    \n",
    "    8.2 Choose Best parameters for Baseline ML Models\n",
    "    \n",
    "10. Baseline for Machine Learning Models with Balanced data and TF-IDF Parameters\n",
    "\n",
    "    10.1 Naive Bayes Base Model (Should be same as 8.1)\n",
    "    \n",
    "    10.2 Logistic Regression Base Model\n",
    "    \n",
    "    10.3 Random Forest Base Model\n",
    "    \n",
    "11. CV ML Models\n",
    "\n",
    "    11.1 Best Naive Bayes Parameters\n",
    "    \n",
    "    11.2 Best Logistic Regression Parameters\n",
    "    \n",
    "    11.3 Best Random Forest Parameters\n",
    "\n",
    "## V. Next Steps (might be able to finish)\n",
    "\n",
    "12. Stemming or Lemmatization\n",
    "\n",
    "13. N-Grams\n",
    "\n",
    "## VI. Next Steps (probably won't be able to finish)\n",
    "14. Deep Learning\n",
    "\n",
    "15. Recommendation System\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I . Setting Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up Spark Session and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Project Notebook\") \\\n",
    "    .config(\"spark.executor.memory\", '16g') \\\n",
    "    .config(\"spark.executor.cores\", '5') \\\n",
    "    .config('spark.cores.max', '5') \\\n",
    "    .config('spark.driver.memory', '16g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers = spark.read.format('csv'). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(\"/home/aaron/BigData135/datasets/beers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = spark.read.format('csv'). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(\"/home/aaron/BigData135/datasets/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- brewery_id: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      " |-- availability: string (nullable = true)\n",
      " |-- abv: string (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- retired: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- beer_id: integer (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: string (nullable = true)\n",
      " |-- smell: string (nullable = true)\n",
      " |-- taste: string (nullable = true)\n",
      " |-- feel: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+-----+-------+--------------------+------------+----+--------------------+-------+\n",
      "|    id|                name|brewery_id|state|country|               style|availability| abv|               notes|retired|\n",
      "+------+--------------------+----------+-----+-------+--------------------+------------+----+--------------------+-------+\n",
      "|202522|      Olde Cogitator|      2199|   CA|     US|English Oatmeal S...|    Rotating| 7.3|No notes at this ...|      f|\n",
      "| 82352|Konrads Stout Rus...|     18604| null|     NO|Russian Imperial ...|    Rotating|10.4|No notes at this ...|      f|\n",
      "|214879|      Scottish Right|     44306|   IN|     US|        Scottish Ale|  Year-round|   4|No notes at this ...|      t|\n",
      "|320009|MegaMeow Imperial...|      4378|   WA|     US|American Imperial...|      Winter| 8.7|Every time this year|      f|\n",
      "|246438|     Peaches-N-Cream|     44617|   PA|     US|  American Cream Ale|    Rotating| 5.1|No notes at this ...|      f|\n",
      "+------+--------------------+----------+-----+-------+--------------------+------------+----+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358873"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               style|count|\n",
      "+--------------------+-----+\n",
      "|        American IPA|44719|\n",
      "|American Pale Ale...|22159|\n",
      "|American Imperial...|18336|\n",
      "|      Belgian Saison|18166|\n",
      "|   American Wild Ale|12972|\n",
      "|American Imperial...|11180|\n",
      "|     American Porter|10168|\n",
      "|American Amber / ...| 9748|\n",
      "|      American Stout| 9103|\n",
      "|Fruit and Field Beer| 7729|\n",
      "| American Blonde Ale| 7089|\n",
      "|  American Brown Ale| 7008|\n",
      "|   German Hefeweizen| 6019|\n",
      "|     Belgian Witbier| 5613|\n",
      "|American Pale Whe...| 5266|\n",
      "|     Berliner Weisse| 5036|\n",
      "|      German Pilsner| 4748|\n",
      "|    Belgian Pale Ale| 4523|\n",
      "|Russian Imperial ...| 4426|\n",
      "|English Sweet / M...| 4192|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many beers in each style\n",
    "beers.groupBy('style').count().sort('count', ascending = False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "|beer_id|       username|               date|                text|                look|               smell| taste|                feel|          overall|             score|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "| 271781|   bluejacket74|2017-03-17 00:00:00|   750 ml bottle,...|                   4|                   4|     4|                4.25|                4|              4.03|\n",
      "| 125646|        _dirty_|2017-12-21 00:00:00|                    |                 4.5|                 4.5|   4.5|                 4.5|              4.5|               4.5|\n",
      "| 125646|        CJDUBYA|2017-12-21 00:00:00|                    |                4.75|                4.75|  4.75|                4.75|             4.75|              4.75|\n",
      "| 125646|GratefulBeerGuy|2017-12-20 00:00:00|\"   0% 16 oz can....| bloomin' like a ...| totally unfilter...| thick| all-white clumps...| mellon and mango| grainy earthiness|\n",
      "| 125646|       LukeGude|2017-12-20 00:00:00|   Classic TH NEI...|                4.25|                 4.5|  4.25|                4.25|             4.25|              4.31|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9073128"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Non Empty Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2987993"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count Non-empty reviews\n",
    "(reviews.filter(reviews['text'] != '\\xa0\\xa0')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_reviews = reviews.filter(reviews['text'] != '\\xa0\\xa0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_reviews = non_empty_reviews.withColumn('text', F.regexp_replace('text', \"\\\\.|\\xa0|!|,|:\", \"\"))\\\n",
    "                                    .withColumn('text', F.trim(F.col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "|beer_id|       username|               date|                text|                look|               smell| taste|                feel|          overall|             score|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "| 271781|   bluejacket74|2017-03-17 00:00:00|750 ml bottle 201...|                   4|                   4|     4|                4.25|                4|              4.03|\n",
      "| 125646|GratefulBeerGuy|2017-12-20 00:00:00|\" 0% 16 oz can Fu...| bloomin' like a ...| totally unfilter...| thick| all-white clumps...| mellon and mango| grainy earthiness|\n",
      "| 125646|       LukeGude|2017-12-20 00:00:00|Classic TH NEIPA ...|                4.25|                 4.5|  4.25|                4.25|             4.25|              4.31|\n",
      "| 125646|           MFMB|2017-12-16 00:00:00|Pours a creamy op...|                4.75|                 4.5|   4.5|                 4.5|              4.5|              4.52|\n",
      "| 125646|    jngrizzaffi|2017-12-10 00:00:00|Pours a cloudy ye...|                 4.5|                 4.5|   4.5|                4.75|              4.5|              4.53|\n",
      "| 125646|       PDOR1960|2017-12-08 00:00:00|Another great bre...|                 4.5|                 4.5|   4.5|                 4.5|              4.5|               4.5|\n",
      "| 125646|        Lucular|2017-12-04 00:00:00|Pours with a clou...|                4.25|                4.25|  4.25|                4.25|             4.25|              4.25|\n",
      "| 205644|    Brutaltruth|2017-03-29 00:00:00|From the tall boy...|                   4|                3.75|     4|                3.75|                4|              3.92|\n",
      "| 205644|    secondtooth|2016-07-13 00:00:00|Appearance Pours ...|                 3.5|                   4|  4.25|                   4|                4|              4.07|\n",
      "| 150672|          Derek|2016-06-07 00:00:00|Beautiful crystal...|                4.75|                   4|  4.25|                4.25|             4.25|              4.22|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_empty_reviews.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT beer_id)|\n",
      "+-----------------------+\n",
      "|                 210311|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Counts how many beers have non-empty reviews\n",
    "non_empty_reviews.agg(F.countDistinct(\"beer_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerStyles = beers.select(\"id\",\"style\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|               style|\n",
      "+------+--------------------+\n",
      "|202522|English Oatmeal S...|\n",
      "| 82352|Russian Imperial ...|\n",
      "|214879|        Scottish Ale|\n",
      "|320009|American Imperial...|\n",
      "|246438|  American Cream Ale|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beerStyles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerStyles = beerStyles.withColumnRenamed('id', 'beer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF = non_empty_reviews.join(beerStyles, \"beer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210294"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainDF.select('beer_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------+\n",
      "|style                   |count |\n",
      "+------------------------+------+\n",
      "|American IPA            |301774|\n",
      "|American Imperial IPA   |212697|\n",
      "|American Imperial Stout |150160|\n",
      "|American Pale Ale (APA) |126489|\n",
      "|Belgian Saison          |91000 |\n",
      "|Russian Imperial Stout  |86117 |\n",
      "|American Porter         |71189 |\n",
      "|American Wild Ale       |63393 |\n",
      "|American Amber / Red Ale|62818 |\n",
      "|Fruit and Field Beer    |58342 |\n",
      "|Belgian Strong Dark Ale |53097 |\n",
      "|Belgian Witbier         |46545 |\n",
      "|Belgian Strong Pale Ale |45732 |\n",
      "|Belgian Tripel          |45686 |\n",
      "|American Brown Ale      |44774 |\n",
      "|American Strong Ale     |43575 |\n",
      "|German Hefeweizen       |42930 |\n",
      "|American Stout          |41879 |\n",
      "|American Barleywine     |40873 |\n",
      "|American Adjunct Lager  |39404 |\n",
      "+------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Counts how many reviews for each style of beer\n",
    "mainDF.groupBy('style').count().sort('count', ascending = False).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|style                   |count|\n",
      "+------------------------+-----+\n",
      "|American IPA            |24380|\n",
      "|American Pale Ale (APA) |12216|\n",
      "|American Imperial IPA   |11517|\n",
      "|Belgian Saison          |9744 |\n",
      "|American Wild Ale       |7390 |\n",
      "|American Imperial Stout |7016 |\n",
      "|American Porter         |5889 |\n",
      "|American Amber / Red Ale|5573 |\n",
      "|American Stout          |4782 |\n",
      "|Fruit and Field Beer    |4471 |\n",
      "|American Brown Ale      |3682 |\n",
      "|German Hefeweizen       |3395 |\n",
      "|American Blonde Ale     |3329 |\n",
      "|Belgian Witbier         |3036 |\n",
      "|German Pilsner          |3024 |\n",
      "|Russian Imperial Stout  |2946 |\n",
      "|American Pale Wheat Ale |2793 |\n",
      "|Belgian Pale Ale        |2630 |\n",
      "|Berliner Weisse         |2586 |\n",
      "|English Bitter          |2545 |\n",
      "+------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Counts how many unique beers of that style is reviewed\n",
    "mainDF.select('beer_id', 'style').distinct().groupBy('style').count().sort('count', ascending = False).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see American Imperial Stout has the 3rd most reviews but only 6th most unique beers. This means that there are a few beers that are American Imperial Stouts with many reviews. We will choose Belgian Saison for classification because it has the 5th most reviews and the 4th most unique beers that have been reviewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecting Targets, Top 4 most reviewed styles (with most unique beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "styleTargets = ['American IPA', 'American Pale Ale (APA)', 'American Imperial IPA', 'Belgian Saison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731960"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainDF.filter(mainDF['style'].isin(styleTargets)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainStyles = mainDF.filter(mainDF['style'].isin(styleTargets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------+\n",
      "|style                  |count |\n",
      "+-----------------------+------+\n",
      "|American IPA           |301774|\n",
      "|American Imperial IPA  |212697|\n",
      "|American Pale Ale (APA)|126489|\n",
      "|Belgian Saison         |91000 |\n",
      "+-----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainStyles.groupBy('style').count().sort('count', ascending = False).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+\n",
      "|style                  |count|\n",
      "+-----------------------+-----+\n",
      "|American IPA           |24380|\n",
      "|American Pale Ale (APA)|12216|\n",
      "|American Imperial IPA  |11517|\n",
      "|Belgian Saison         |9744 |\n",
      "+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainStyles.select('beer_id', 'style').distinct().groupBy('style').count().sort('count', ascending = False).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- beer_id: integer (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: string (nullable = true)\n",
      " |-- smell: string (nullable = true)\n",
      " |-- taste: string (nullable = true)\n",
      " |-- feel: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainStyles.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Should Remove rows with NA's and Text in Numerical Columns\n",
    "model_df = mainStyles.filter(F.col(\"look\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"smell\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"taste\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"feel\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"overall\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"score\").cast(\"int\").isNotNull() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast Numerical columns as floats now that strings and na's are removed\n",
    "model_df = model_df.withColumn('look', model_df['look'].cast(\"float\"))\\\n",
    "        .withColumn('smell', model_df['smell'].cast(\"float\"))\\\n",
    "        .withColumn('taste', model_df['taste'].cast(\"float\"))\\\n",
    "        .withColumn('feel', model_df['feel'].cast(\"float\"))\\\n",
    "        .withColumn('overall', model_df['overall'].cast(\"float\"))\\\n",
    "        .withColumn('score', model_df['score'].cast(\"float\"))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df.drop(\"username\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-----+-----+----+-------+-----+-----+\n",
      "|beer_id|text|look|smell|taste|feel|overall|score|style|\n",
      "+-------+----+----+-----+-----+----+-------+-----+-----+\n",
      "|      0|   0|   0|    0|    0|   0|      0|    0|    0|\n",
      "+-------+----+----+-----+-----+----+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last check for NA's\n",
    "model_df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in model_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- beer_id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: float (nullable = true)\n",
      " |-- smell: float (nullable = true)\n",
      " |-- taste: float (nullable = true)\n",
      " |-- feel: float (nullable = true)\n",
      " |-- overall: float (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Exploratory Analysis and Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison of Means for Each Style and Summary Statistics for Entire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|               style|         avg(look)|        avg(smell)|        avg(taste)|         avg(feel)|      avg(overall)|        avg(score)|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|        American IPA| 3.986425988960963|3.9190130602160207|3.9318579356773973|3.9012531309383935|3.9446924219012685| 3.932736264468442|\n",
      "|American Imperial...| 4.107345298701574|4.0981487760042805|4.1012994856092435| 4.058349711549159|4.0595800643120885| 4.089419074101148|\n",
      "|American Pale Ale...|3.8744497214357474|3.7821011051237554|3.8132181021097815|3.7911087770572656|3.8725111882363685|3.8200986432859327|\n",
      "|      Belgian Saison|3.9922546618708705|3.9455913114461367|3.9475109053340476|3.9248201576490396| 3.955256243463177|3.9501903062389685|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.groupBy('style')\\\n",
    "        .agg(F.mean('look'), F.mean('smell'), F.mean('taste'), F.mean('feel'), F.mean('overall'),\n",
    "            F.mean('score')).show(truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+--------------+\n",
      "|summary|          beer_id|                text|              look|             smell|             taste|              feel|           overall|            score|         style|\n",
      "+-------+-----------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+--------------+\n",
      "|  count|           641356|              641356|            641356|            641356|            641356|            641356|            641356|           641356|        641356|\n",
      "|   mean|86016.15441190229|            145855.5| 4.003611878582253|3.9516130666899505|3.9633885080984665| 3.931568037096402|3.9674755517996245|3.961756469417888|          null|\n",
      "| stddev|86104.03033777044|   995375.9829575884|0.4889811619131977|0.5641361351138886|0.5939057486341173|0.5428806486968022|0.5714921030640363|0.508148213541669|          null|\n",
      "|    min|                3|                    |               1.0|               1.0|               1.0|               1.0|               1.0|              1.0|  American IPA|\n",
      "|    max|           372836|￼Really well done...|               5.0|               5.0|               5.0|               5.0|               5.0|              5.0|Belgian Saison|\n",
      "+-------+-----------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setting Up Pipelines \n",
    "\n",
    "### Note: HashingTF and IDF are updated with best parameters from parts 7 and 8 below. During the initial running of part 6 (before cross validation or undersampling) we used default parameters\n",
    "\n",
    "Note: The Random Forest ParamGrid and Cross Validator have been removed for reasons that can be found later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"text\", outputCol = \"words\")\n",
    "stopRem = StopWordsRemover(inputCol = 'words', outputCol = 'filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipe1 = Pipeline(stages = [tokenizer, stopRem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text = text_pipe1.fit(model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text_df = token_text.transform(model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmer_udf = F.udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "df_stemmed = token_text_df.withColumn(\"words_stemmed\", stemmer_udf(\"filtered\")).select('words_stemmed', 'style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol = \"words_stemmed\", outputCol = \"rawFeatures\", numFeatures = 50000)\n",
    "idf = IDF(inputCol = \"rawFeatures\", outputCol = \"features\", minDocFreq = 1000)\n",
    "stringIdx = StringIndexer(inputCol = 'style', outputCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = MulticlassClassificationEvaluator(predictionCol = \"prediction\", metricName = 'accuracy')\n",
    "f1 = MulticlassClassificationEvaluator(predictionCol = \"prediction\", metricName = 'f1')\n",
    "rec = MulticlassClassificationEvaluator(predictionCol = \"prediction\", metricName = 'weightedRecall')\n",
    "prec = MulticlassClassificationEvaluator(predictionCol = \"prediction\", metricName = 'weightedPrecision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "pipelineNB = Pipeline(stages=[hashingTF, idf, stringIdx, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label')\n",
    "pipelineLogReg = Pipeline(stages=[hashingTF, idf, stringIdx, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol = \"label\", featuresCol = \"features\", numTrees = 20, maxDepth = 10, maxBins = 32)\n",
    "pipelineRF = Pipeline(stages = [hashingTF, idf, stringIdx, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc = MultilayerPerceptronClassifier(labelCol = \"label\", featuresCol = \"features\", layers = [50000, 25002, 4])\n",
    "pipelineMLPC = Pipeline(stages = [hashingTF, idf, stringIdx, mlpc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridTFIDF = ParamGridBuilder()\\\n",
    "    .addGrid(hashingTF.numFeatures, [1000, 10000, 50000, 100000])\\\n",
    "    .addGrid(idf.minDocFreq, [100, 1000, 10000])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridNB = ParamGridBuilder()\\\n",
    "    .addGrid(nb.smoothing, [0.001, 0.01, 0.1, 0.5, 1, 1.5, 1.75])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridLogReg = ParamGridBuilder()\\\n",
    "    .addGrid(lr.maxIter, [10, 50, 100])\\\n",
    "    .addGrid(lr.regParam, np.linspace(0,1,5))\\\n",
    "    .addGrid(lr.elasticNetParam, np.linspace(0,1,5))\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvTFIDF = CrossValidator(estimator = pipelineNB,\n",
    "                              estimatorParamMaps = paramGridTFIDF,\n",
    "                              evaluator = acc,\n",
    "                              numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvNB = CrossValidator(estimator = pipelineNB,\n",
    "                         estimatorParamMaps = paramGridNB,\n",
    "                         evaluator = acc,\n",
    "                         numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvLogReg = CrossValidator(estimator = pipelineLogReg,\n",
    "                         estimatorParamMaps = paramGridLogReg,\n",
    "                         evaluator = acc,\n",
    "                         numFolds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "- Unbalanced\n",
    "- No subset/sample of data\n",
    "- No N-Grams\n",
    "- NO TF-IDF parameters\n",
    "- Use default Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641356"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               style| count|\n",
      "+--------------------+------+\n",
      "|        American IPA|264697|\n",
      "|American Imperial...|188767|\n",
      "|American Pale Ale...|109490|\n",
      "|      Belgian Saison| 78402|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.groupBy('style').count().sort('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDat, testDat = data1.randomSplit([0.8, 0.2], seed = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfModBase = pipelineNB.fit(trainDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTfidfBase = tfidfModBase.transform(testDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6329892536841992"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predTfidfBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampled Data Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSampled = data1.sampleBy(\"style\", fractions={\"American IPA\": 75000/264697,\n",
    "                                                \"American Imperial IPA\": 75000/188767,\n",
    "                                                \"American Pale Ale (APA)\": 75000/109490,\n",
    "                                                \"Belgian Saison\": 75000/78402}, seed = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299780"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSampled.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               style|count|\n",
      "+--------------------+-----+\n",
      "|        American IPA|74787|\n",
      "|American Imperial...|74850|\n",
      "|American Pale Ale...|75127|\n",
      "|      Belgian Saison|75016|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataSampled.groupBy(\"style\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDatSample, HoldoutDatSample = dataSampled.randomSplit([0.8, 0.2], seed = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseTFidfModSamp = pipelineNB.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predBaseTfidfModSamp = baseTFidfModSamp.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571791787364042"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.evaluate(predBaseTfidfModSamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvTfidfBaseSamp = cvTFIDF.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predCvTfidfBaseSamp = cvTfidfBaseSamp.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110905820464676"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.evaluate(predCvTfidfBaseSamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6788381546265239,\n",
       " 0.6790195465063918,\n",
       " 0.6511097864367734,\n",
       " 0.7038010489528553,\n",
       " 0.7102504991749712,\n",
       " 0.672852305377929,\n",
       " 0.7079868334029631,\n",
       " 0.7104003885353377,\n",
       " 0.6736301027553668,\n",
       " 0.7086800568599321,\n",
       " 0.7102314892232567,\n",
       " 0.6732559461899431]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvTfidfBaseSamp.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='CrossValidatorModel_5d14e43b9601', name='seed', doc='random seed.'): 3088197668997532376,\n",
       " Param(parent='CrossValidatorModel_5d14e43b9601', name='estimator', doc='estimator to be cross-validated'): Pipeline_c4e2eb62be3d,\n",
       " Param(parent='CrossValidatorModel_5d14e43b9601', name='estimatorParamMaps', doc='estimator param maps'): [{Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 1000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 100},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 1000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 1000},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 1000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 10000},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 10000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 100},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 10000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 1000},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 10000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 10000},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 50000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 100},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 50000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 1000},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 50000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 10000},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 100000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 100},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 100000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 1000},\n",
       "  {Param(parent='HashingTF_dfabdfbac44b', name='numFeatures', doc='number of features.'): 100000,\n",
       "   Param(parent='IDF_7e0d9f648ee9', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 10000}],\n",
       " Param(parent='CrossValidatorModel_5d14e43b9601', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'): MulticlassClassificationEvaluator_1a8e558913b8}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvTfidfBaseSamp.extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best TF-IDF Parameters\n",
    "1. numFeatures = 50000, minDocFreq = 1000\n",
    "2. numFeatures = 100000, minDocFreq = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbModSamp = pipelineNB.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predNbModSamp = nbModSamp.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110988570282735"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy: ', acc.evaluate(predNbModSamp))\n",
    "print('F1: ', f1.evaluate(predNbModSamp))\n",
    "print('Recall: ', rec.evaluate(predNbModSamp))\n",
    "print('Precision: ', prec.evaluate(predNbModSamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "logModSamp = pipelineLogReg.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predLogModSamp = logModSamp.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7504344629369695\n",
      "F1:  0.7482493618992855\n",
      "Recall:  0.7504344629369694\n",
      "Precision:  0.7475033564050357\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', acc.evaluate(predLogModSamp))\n",
    "print('F1: ', f1.evaluate(predLogModSamp))\n",
    "print('Recall: ', rec.evaluate(predLogModSamp))\n",
    "print('Precision: ', prec.evaluate(predLogModSamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModSamp = pipelineRF.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predRfModSamp = rfModSamp.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.567530442615334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy: ', acc.evaluate(predRfModSamp))\n",
    "print('F1: ', f1.evaluate(predRfModSamp))\n",
    "print('Recall: ', rec.evaluate(predRfModSamp))\n",
    "print('Precision: ', prec.evaluate(predRfModSamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Random Forest takes too long to compute and the results are not as good as Naive Bayes or Logistic Regression, we will not proceed with Random Forest as an option for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpcModSamp = pipelineMLPC.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predMlpcModSamp = mlpcModSamp.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', acc.evaluate(predMlpcModSamp))\n",
    "print('F1: ', f1.evaluate(predMlpcModSamp))\n",
    "print('Recall: ', rec.evaluate(predMlpcModSamp))\n",
    "print('Precision: ', prec.evaluate(predMlpcModSamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbCvMod = cvNB.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predNbCvMod = nbCvMod.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115170506259193"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy: ', acc.evaluate(predNbCvMod))\n",
    "print('F1: ', f1.evaluate(predNbCvMod))\n",
    "print('Recall: ', rec.evaluate(predNbCvMod))\n",
    "print('Precision: ', prec.evaluate(predNbCvMod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7105149973310461,\n",
       " 0.7105176994229886,\n",
       " 0.7104524603679008,\n",
       " 0.7103617198635772,\n",
       " 0.7102794035437655,\n",
       " 0.710155793264444,\n",
       " 0.7101130247303079]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbCvMod.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='CrossValidatorModel_b51da40081ef', name='seed', doc='random seed.'): -6010773883408694140,\n",
       " Param(parent='CrossValidatorModel_b51da40081ef', name='estimator', doc='estimator to be cross-validated'): Pipeline_e0850fd4288c,\n",
       " Param(parent='CrossValidatorModel_b51da40081ef', name='estimatorParamMaps', doc='estimator param maps'): [{Param(parent='NaiveBayes_fdb502dfb0d7', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.001},\n",
       "  {Param(parent='NaiveBayes_fdb502dfb0d7', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.01},\n",
       "  {Param(parent='NaiveBayes_fdb502dfb0d7', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.1},\n",
       "  {Param(parent='NaiveBayes_fdb502dfb0d7', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.5},\n",
       "  {Param(parent='NaiveBayes_fdb502dfb0d7', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 1.0},\n",
       "  {Param(parent='NaiveBayes_fdb502dfb0d7', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 1.5},\n",
       "  {Param(parent='NaiveBayes_fdb502dfb0d7', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 1.75}],\n",
       " Param(parent='CrossValidatorModel_b51da40081ef', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'): MulticlassClassificationEvaluator_8d2ce3358ac8}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbCvMod.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logRegCvMod = cvLogReg.fit(TrainDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predLogRegCvMod = logRegCvMod.transform(HoldoutDatSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', acc.evaluate(predLogRegCvMod))\n",
    "print('F1: ', f1.evaluate(predLogRegCvMod))\n",
    "print('Recall: ', rec.evaluate(predLogRegCvMod))\n",
    "print('Precision: ', prec.evaluate(predLogRegCvMod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
