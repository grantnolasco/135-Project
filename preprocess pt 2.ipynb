{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import regexp_replace,col\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Exploratory_Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config(\"spark.executor.cores\", '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config('spark.driver.memory', '8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers = spark.read.format('csv'). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(\"C:/Users/Eri/Documents/PSTAT 135/beers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries = spark.read.format('csv'). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(\"C:/Users/Eri/Documents/PSTAT 135/breweries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = spark.read.format('csv'). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(\"C:/Users/Eri/Documents/PSTAT 135/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- brewery_id: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      " |-- availability: string (nullable = true)\n",
      " |-- abv: string (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- retired: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- types: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "breweries.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- beer_id: integer (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: string (nullable = true)\n",
      " |-- smell: string (nullable = true)\n",
      " |-- taste: string (nullable = true)\n",
      " |-- feel: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+-----+-------+--------------------+------------+----+--------------------+-------+\n",
      "|    id|                name|brewery_id|state|country|               style|availability| abv|               notes|retired|\n",
      "+------+--------------------+----------+-----+-------+--------------------+------------+----+--------------------+-------+\n",
      "|202522|      Olde Cogitator|      2199|   CA|     US|English Oatmeal S...|    Rotating| 7.3|No notes at this ...|      f|\n",
      "| 82352|Konrads Stout Rus...|     18604| null|     NO|Russian Imperial ...|    Rotating|10.4|No notes at this ...|      f|\n",
      "|214879|      Scottish Right|     44306|   IN|     US|        Scottish Ale|  Year-round|   4|No notes at this ...|      t|\n",
      "|320009|MegaMeow Imperial...|      4378|   WA|     US|American Imperial...|      Winter| 8.7|Every time this year|      f|\n",
      "|246438|     Peaches-N-Cream|     44617|   PA|     US|  American Cream Ale|    Rotating| 5.1|No notes at this ...|      f|\n",
      "+------+--------------------+----------+-----+-------+--------------------+------------+----+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358873"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               style|count|\n",
      "+--------------------+-----+\n",
      "|        American IPA|44719|\n",
      "|American Pale Ale...|22159|\n",
      "|American Imperial...|18336|\n",
      "|      Belgian Saison|18166|\n",
      "|   American Wild Ale|12972|\n",
      "|American Imperial...|11180|\n",
      "|     American Porter|10168|\n",
      "|American Amber / ...| 9748|\n",
      "|      American Stout| 9103|\n",
      "|Fruit and Field Beer| 7729|\n",
      "| American Blonde Ale| 7089|\n",
      "|  American Brown Ale| 7008|\n",
      "|   German Hefeweizen| 6019|\n",
      "|     Belgian Witbier| 5613|\n",
      "|American Pale Whe...| 5266|\n",
      "|     Berliner Weisse| 5036|\n",
      "|      German Pilsner| 4748|\n",
      "|    Belgian Pale Ale| 4523|\n",
      "|Russian Imperial ...| 4426|\n",
      "|English Sweet / M...| 4192|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beers.groupBy('style').count().sort('count', ascending = False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------+-----+-------+--------------------+--------------------+\n",
      "|   id|                name|          city|state|country|               notes|               types|\n",
      "+-----+--------------------+--------------+-----+-------+--------------------+--------------------+\n",
      "|19730|     Brouwerij Danny|     Erpe-Mere| null|     BE|No notes at this ...|             Brewery|\n",
      "|32541|Coachella Valley ...|Thousand Palms|   CA|     US|No notes at this ...|Brewery, Bar, Bee...|\n",
      "|44736|    Beef 'O' Brady's|    Plant City|   FL|     US|No notes at this ...|         Bar, Eatery|\n",
      "|23372|Broadway Wine Mer...| Oklahoma City|   OK|     US|No notes at this ...|               Store|\n",
      "|35328|Brighton Beer Dis...|      Brighton|  GB2|     GB|Duplicate of http...|         Bar, Eatery|\n",
      "+-----+--------------------+--------------+-----+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "breweries.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "|beer_id|       username|               date|                text|                look|               smell| taste|                feel|          overall|             score|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "| 271781|   bluejacket74|2017-03-17 00:00:00|   750 ml bottle,...|                   4|                   4|     4|                4.25|                4|              4.03|\n",
      "| 125646|        _dirty_|2017-12-21 00:00:00|                    |                 4.5|                 4.5|   4.5|                 4.5|              4.5|               4.5|\n",
      "| 125646|        CJDUBYA|2017-12-21 00:00:00|                    |                4.75|                4.75|  4.75|                4.75|             4.75|              4.75|\n",
      "| 125646|GratefulBeerGuy|2017-12-20 00:00:00|\"   0% 16 oz can....| bloomin' like a ...| totally unfilter...| thick| all-white clumps...| mellon and mango| grainy earthiness|\n",
      "| 125646|       LukeGude|2017-12-20 00:00:00|   Classic TH NEI...|                4.25|                 4.5|  4.25|                4.25|             4.25|              4.31|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2987993"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reviews.filter(reviews['text'] != '\\xa0\\xa0')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_reviews = reviews.filter(reviews['text'] != '\\xa0\\xa0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "|beer_id|       username|               date|                text|                look|               smell| taste|                feel|          overall|             score|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "| 271781|   bluejacket74|2017-03-17 00:00:00|   750 ml bottle,...|                   4|                   4|     4|                4.25|                4|              4.03|\n",
      "| 125646|GratefulBeerGuy|2017-12-20 00:00:00|\"   0% 16 oz can....| bloomin' like a ...| totally unfilter...| thick| all-white clumps...| mellon and mango| grainy earthiness|\n",
      "| 125646|       LukeGude|2017-12-20 00:00:00|   Classic TH NEI...|                4.25|                 4.5|  4.25|                4.25|             4.25|              4.31|\n",
      "| 125646|           MFMB|2017-12-16 00:00:00|   Pours a creamy...|                4.75|                 4.5|   4.5|                 4.5|              4.5|              4.52|\n",
      "| 125646|    jngrizzaffi|2017-12-10 00:00:00|   Pours a cloudy...|                 4.5|                 4.5|   4.5|                4.75|              4.5|              4.53|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_empty_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beer_id', 'int'),\n",
       " ('username', 'string'),\n",
       " ('date', 'timestamp'),\n",
       " ('text', 'string'),\n",
       " ('look', 'string'),\n",
       " ('smell', 'string'),\n",
       " ('taste', 'string'),\n",
       " ('feel', 'string'),\n",
       " ('overall', 'string'),\n",
       " ('score', 'string')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dtype = datatype \n",
    "non_empty_reviews.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|          beer_id|            username|                text|                look|               smell|               taste|                feel|             overall|               score|\n",
      "+-------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|          2987993|             2984209|             2987993|             2831961|             2830771|             2829717|             2828842|             2828088|             2983385|\n",
      "|   mean|63296.20292818624|1.8038932242394958E9|                null|  3.9394156210280866|  3.8445426409163534|   3.870134391442983|   3.835104948841218|   3.864983629690377|  3.8468598629637483|\n",
      "| stddev|76771.34267413334|1.428156622016932...|                null|   8.434001006900342|   7.575114374811774|   5.368186049630725|  14.241445214619425|   3.062086369033622|  2.4322625660259987|\n",
      "|    min|                3|             --Dom--|\"   ! Gusher warn...|                    |                    |                    |                    |                    |                    |\n",
      "|    max|           373128|             zzombie|   ￼Really well d...|” which is exactl...|” cuz they leave ...|” meaning the bre...| I was hoping th...| with a hint of o...|” as Felix says. ...|\n",
      "+-------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_empty_reviews.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|beer_id|       username|               date|                text|                look|               smell|               taste|                feel|             overall|               score|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 125646|GratefulBeerGuy|2017-12-20 00:00:00|\"   0% 16 oz can....| bloomin' like a ...| totally unfilter...|               thick| all-white clumps...|    mellon and mango|   grainy earthiness|\n",
      "| 206623|   rodbeermunch|2016-01-27 00:00:00|\"   Dark brown po...| whisps away quic...| possibly the bes...| good irish malt ...| bourbon and oak ...| relatively easy ...| good bourbon del...|\n",
      "|  96331|       dirtylou|2013-07-09 00:00:00|\"   on-tap @ the ...| dank hops - mode...|  nice sugary citrus|     doughy malt.  \"|                null|                null|                null|\n",
      "|  58482|     hosehead83|2009-07-27 00:00:00|\"   poured into a...| a bit more hop i...| but upon warming...| not too bad and ...|                 3.5|                 3.5|                   4|\n",
      "|  58482|      maximum12|2009-07-19 00:00:00|\"   Big thanks to...| & a successful o...|                   4|                   4|                   4|                 3.5|                   4|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_empty_reviews.filter(F.col(\"look\").cast(\"int\").isNotNull() == False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372068"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty_reviews.filter(F.col(\"look\").cast(\"int\").isNotNull() == False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12452104138128837"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "372068/2987993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|beer_id|count|\n",
      "+-------+-----+\n",
      "|    645| 4364|\n",
      "|  11757| 4300|\n",
      "|   2093| 4252|\n",
      "|   7971| 4155|\n",
      "|   1093| 4054|\n",
      "|    412| 4001|\n",
      "|  17112| 3905|\n",
      "|    695| 3786|\n",
      "|  19960| 3738|\n",
      "|   1904| 3675|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_empty_reviews.groupBy('beer_id').count().sort('count', ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT beer_id)|\n",
      "+-----------------------+\n",
      "|                 210311|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_empty_reviews.agg(F.countDistinct(\"beer_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerStyles = beers.select(\"id\",\"style\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|               style|\n",
      "+------+--------------------+\n",
      "|202522|English Oatmeal S...|\n",
      "| 82352|Russian Imperial ...|\n",
      "|214879|        Scottish Ale|\n",
      "|320009|American Imperial...|\n",
      "|246438|  American Cream Ale|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beerStyles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerStyles = beerStyles.withColumnRenamed('id', 'beer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|beer_id|               style|\n",
      "+-------+--------------------+\n",
      "| 202522|English Oatmeal S...|\n",
      "|  82352|Russian Imperial ...|\n",
      "| 214879|        Scottish Ale|\n",
      "| 320009|American Imperial...|\n",
      "| 246438|  American Cream Ale|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beerStyles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joint dataframe with review + beer style \n",
    "test = non_empty_reviews.join(beerStyles, \"beer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+--------------------+\n",
      "|beer_id|       username|               date|                text|                look|               smell| taste|                feel|          overall|             score|               style|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+--------------------+\n",
      "| 271781|   bluejacket74|2017-03-17 00:00:00|   750 ml bottle,...|                   4|                   4|     4|                4.25|                4|              4.03|American Imperial...|\n",
      "| 125646|GratefulBeerGuy|2017-12-20 00:00:00|\"   0% 16 oz can....| bloomin' like a ...| totally unfilter...| thick| all-white clumps...| mellon and mango| grainy earthiness|     New England IPA|\n",
      "| 125646|       LukeGude|2017-12-20 00:00:00|   Classic TH NEI...|                4.25|                 4.5|  4.25|                4.25|             4.25|              4.31|     New England IPA|\n",
      "| 125646|           MFMB|2017-12-16 00:00:00|   Pours a creamy...|                4.75|                 4.5|   4.5|                 4.5|              4.5|              4.52|     New England IPA|\n",
      "| 125646|    jngrizzaffi|2017-12-10 00:00:00|   Pours a cloudy...|                 4.5|                 4.5|   4.5|                4.75|              4.5|              4.53|     New England IPA|\n",
      "+-------+---------------+-------------------+--------------------+--------------------+--------------------+------+--------------------+-----------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2987925"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               style| count|\n",
      "+--------------------+------+\n",
      "|        American IPA|301774|\n",
      "|American Imperial...|212697|\n",
      "|American Imperial...|150160|\n",
      "|American Pale Ale...|126489|\n",
      "|      Belgian Saison| 91000|\n",
      "|Russian Imperial ...| 86117|\n",
      "|     American Porter| 71189|\n",
      "|   American Wild Ale| 63393|\n",
      "|American Amber / ...| 62818|\n",
      "|Fruit and Field Beer| 58342|\n",
      "|Belgian Strong Da...| 53097|\n",
      "|     Belgian Witbier| 46545|\n",
      "|Belgian Strong Pa...| 45732|\n",
      "|      Belgian Tripel| 45686|\n",
      "|  American Brown Ale| 44774|\n",
      "| American Strong Ale| 43575|\n",
      "|   German Hefeweizen| 42930|\n",
      "|      American Stout| 41879|\n",
      "| American Barleywine| 40873|\n",
      "|American Adjunct ...| 39404|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy('style').count().sort('count', ascending = False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+\n",
      "|beer_id|               style|count|\n",
      "+-------+--------------------+-----+\n",
      "|    645|Belgian Quadrupel...| 4364|\n",
      "|  11757|American Imperial...| 4300|\n",
      "|   2093|American Imperial...| 4252|\n",
      "|   7971|American Imperial...| 4155|\n",
      "|   1093|        American IPA| 4054|\n",
      "|    412|Russian Imperial ...| 4001|\n",
      "|  17112|American Imperial...| 3905|\n",
      "|    695|Belgian Strong Pa...| 3786|\n",
      "|  19960|American Imperial...| 3738|\n",
      "|   1904|        American IPA| 3675|\n",
      "|  10672|American Imperial...| 3422|\n",
      "|    276|American Pale Ale...| 3312|\n",
      "|     88|        American IPA| 3304|\n",
      "|     92| American Strong Ale| 3280|\n",
      "|  30420|        American IPA| 3234|\n",
      "|   4083|American Imperial...| 3196|\n",
      "|   2671| American Barleywine| 3175|\n",
      "|     34|      Belgian Tripel| 3160|\n",
      "|  16814|     New England IPA| 3081|\n",
      "|   1708|Belgian Quadrupel...| 3043|\n",
      "+-------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy(['beer_id', 'style']).count().sort('count', ascending = False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210294"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select('beer_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------+\n",
      "|beer_id|concat_ws(; , collect_list(text))|\n",
      "+-------+---------------------------------+\n",
      "|    148|                This one was s...|\n",
      "|    463|                22oz : tulip C...|\n",
      "|    471|                Pours a clear,...|\n",
      "|    496|                Presentation: ...|\n",
      "|    833|                Out of the sum...|\n",
      "|   1088|                Midnight Sun O...|\n",
      "|   1238|                From a six-pac...|\n",
      "|   1580|                This beer is a...|\n",
      "|   1591|                Very good wint...|\n",
      "|   1645|                Poured into sn...|\n",
      "|   1959|                Okay beer. Not...|\n",
      "|   2122|                Muddy and thic...|\n",
      "|   2142|                Had on tap. Ni...|\n",
      "|   2659|                This beer pour...|\n",
      "|   2866|                Fair head for ...|\n",
      "|   3175|             \"   This was serv...|\n",
      "|   3794|                Tan head settl...|\n",
      "|   3918|                12oz bottle po...|\n",
      "|   3997|                Pours a clear ...|\n",
      "|   4519|                Clear brown co...|\n",
      "+-------+---------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy('beer_id').agg(F.concat_ws('; ', F.collect_list('text'))).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedReviews = test.groupBy('beer_id').agg(F.concat_ws(' ', F.collect_list('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "countStyles = combinedReviews.join(beerStyles, \"beer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------+--------------------+\n",
      "|beer_id|concat_ws( , collect_list(text))|               style|\n",
      "+-------+--------------------------------+--------------------+\n",
      "|    148|               This one was s...|American Amber / ...|\n",
      "+-------+--------------------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countStyles.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|style                   |count|\n",
      "+------------------------+-----+\n",
      "|American IPA            |24380|\n",
      "|American Pale Ale (APA) |12216|\n",
      "|American Imperial IPA   |11517|\n",
      "|Belgian Saison          |9744 |\n",
      "|American Wild Ale       |7390 |\n",
      "|American Imperial Stout |7016 |\n",
      "|American Porter         |5889 |\n",
      "|American Amber / Red Ale|5573 |\n",
      "|American Stout          |4782 |\n",
      "|Fruit and Field Beer    |4471 |\n",
      "+------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countStyles.groupBy('style').count().sort('count', ascending = False).show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "styleTargets = ['American IPA', 'American Pale Ale (APA)', 'American Imperial IPA', 'Belgian Saison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731960"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.filter(test['style'].isin(styleTargets)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainStyles = test.filter(test['style'].isin(styleTargets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- beer_id: integer (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: string (nullable = true)\n",
      " |-- smell: string (nullable = true)\n",
      " |-- taste: string (nullable = true)\n",
      " |-- feel: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainStyles.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641356"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainStyles.filter(F.col(\"look\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"smell\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"taste\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"feel\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"overall\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"score\").cast(\"int\").isNotNull() == True)\\\n",
    "            .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model_df from mainStyles (has top 4 styles)\n",
    "model_df = mainStyles.filter(F.col(\"look\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"smell\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"taste\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"feel\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"overall\").cast(\"int\").isNotNull() == True)\\\n",
    "            .filter(F.col(\"score\").cast(\"int\").isNotNull() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df.drop(\"username\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- beer_id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: string (nullable = true)\n",
      " |-- smell: string (nullable = true)\n",
      " |-- taste: string (nullable = true)\n",
      " |-- feel: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----+-----+-----+----+-------+-----+------------+\n",
      "|beer_id|                text|look|smell|taste|feel|overall|score|       style|\n",
      "+-------+--------------------+----+-----+-----+----+-------+-----+------------+\n",
      "| 150672|   Beautiful, cry...|4.75|    4| 4.25|4.25|   4.25| 4.22|American IPA|\n",
      "| 150672|   Poured a bit l...|3.75| 3.75| 3.75|3.75|   3.75| 3.75|American IPA|\n",
      "| 150672|   355ml can. Bri...|4.25|    4|    4|4.25|      4| 4.04|American IPA|\n",
      "| 150672|   Quite balanced...|4.25|  4.5| 4.25| 4.5|   4.25| 4.34|American IPA|\n",
      "| 150672|   Can: Poured a ...|3.75| 3.75| 3.75|3.75|   3.75| 3.75|American IPA|\n",
      "+-------+--------------------+----+-----+-----+----+-------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               style| count|\n",
      "+--------------------+------+\n",
      "|        American IPA|264697|\n",
      "|American Imperial...|188767|\n",
      "|American Pale Ale...|109490|\n",
      "|      Belgian Saison| 78402|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.groupBy('style').count().sort('count', ascending = False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+\n",
      "|beer_id|               style|count|\n",
      "+-------+--------------------+-----+\n",
      "|   2093|American Imperial...| 3808|\n",
      "|   7971|American Imperial...| 3706|\n",
      "|   1093|        American IPA| 3680|\n",
      "|  17112|American Imperial...| 3525|\n",
      "|   1904|        American IPA| 3321|\n",
      "|    276|American Pale Ale...| 3000|\n",
      "|     88|        American IPA| 2971|\n",
      "|  30420|        American IPA| 2876|\n",
      "|   4083|American Imperial...| 2793|\n",
      "|  29619|        American IPA| 2665|\n",
      "|   1005|        American IPA| 2416|\n",
      "|   2751|        American IPA| 2264|\n",
      "|   9086|American Imperial...| 2260|\n",
      "|  35738|American Imperial...| 2116|\n",
      "|    141|      Belgian Saison| 2085|\n",
      "|   5441|        American IPA| 2036|\n",
      "|   6108|        American IPA| 1989|\n",
      "|   3158|        American IPA| 1941|\n",
      "|     39|American Pale Ale...| 1890|\n",
      "|   6518|American Pale Ale...| 1879|\n",
      "+-------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.groupBy(['beer_id', 'style']).count().sort('count', ascending = False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df.drop('beer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: string (nullable = true)\n",
      " |-- smell: string (nullable = true)\n",
      " |-- taste: string (nullable = true)\n",
      " |-- feel: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df.withColumn('look', model_df['look'].cast(\"float\"))\\\n",
    "        .withColumn('smell', model_df['smell'].cast(\"float\"))\\\n",
    "        .withColumn('feel', model_df['feel'].cast(\"float\"))\\\n",
    "        .withColumn('taste', model_df['taste'].cast(\"float\"))\\\n",
    "        .withColumn('overall', model_df['overall'].cast(\"float\"))\\\n",
    "        .withColumn('score', model_df['score'].cast(\"float\"))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: float (nullable = true)\n",
      " |-- smell: float (nullable = true)\n",
      " |-- taste: float (nullable = true)\n",
      " |-- feel: float (nullable = true)\n",
      " |-- overall: float (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|               style|         avg(look)|        avg(smell)|        avg(taste)|         avg(feel)|      avg(overall)|        avg(score)|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|        American IPA| 3.986425988960963|3.9190130602160207|3.9318579356773973|3.9012531309383935|3.9446924219012685| 3.932736264468442|\n",
      "|American Imperial...| 4.107345298701574|4.0981487760042805|4.1012994856092435| 4.058349711549159|4.0595800643120885| 4.089419074101148|\n",
      "|American Pale Ale...|3.8744497214357474|3.7821011051237554|3.8132181021097815|3.7911087770572656|3.8725111882363685|3.8200986432859327|\n",
      "|      Belgian Saison|3.9922546618708705|3.9455913114461367|3.9475109053340476|3.9248201576490396| 3.955256243463177|3.9501903062389685|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.groupBy('style')\\\n",
    "        .agg(F.mean('look'), F.mean('smell'), F.mean('taste'), F.mean('feel'), F.mean('overall'),\n",
    "            F.mean('score')).show(truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- look: float (nullable = true)\n",
      " |-- smell: float (nullable = true)\n",
      " |-- taste: float (nullable = true)\n",
      " |-- feel: float (nullable = true)\n",
      " |-- overall: float (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace,col\n",
    "data1 = model_df.select('text', 'style')\n",
    "#for multiple regex expressions use OR |\n",
    "data1 = data1.withColumn('text', regexp_replace(col('text'), \"\\\\.|\\xa0|!|,|:\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                text|       style|\n",
      "+--------------------+------------+\n",
      "| Beautiful crysta...|American IPA|\n",
      "| Poured a bit liv...|American IPA|\n",
      "| 355ml can Bright...|American IPA|\n",
      "| Quite balanced a...|American IPA|\n",
      "| Can Poured a cle...|American IPA|\n",
      "| Can bought onlin...|American IPA|\n",
      "| Passing through ...|American IPA|\n",
      "| Yes please I've ...|American IPA|\n",
      "| A well put toget...|American IPA|\n",
      "| 355ml can the la...|American IPA|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of white space and separate each word \n",
    "data1 = data1.withColumn('text', split(data1['text'], ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.withColumn('text', array_remove('text', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words \n",
    "remover = StopWordsRemover(inputCol=\"text\", outputCol=\"filtered\")\n",
    "data2 = remover.transform(data1)\n",
    "data2 = data2.select('filtered', 'style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6bf2c34cea0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data2' is not defined"
     ]
    }
   ],
   "source": [
    "data2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([('abcd','123')], ['s', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = data2.groupby('style').agg(F.collect_list('filtered').alias(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               style|                text|\n",
      "+--------------------+--------------------+\n",
      "|        American IPA|[[Beautiful, crys...|\n",
      "|American Imperial...|[[Drank, 6/6/18, ...|\n",
      "|American Pale Ale...|[[16oz, PKG, 5/8/...|\n",
      "|      Belgian Saison|[[0%], [tap, CBC,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make into rdd \n",
    "dat = grouped_df.rdd.map(lambda x : ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 96.0 failed 1 times, most recent failure: Lost task 0.0 in stage 96.0 (TID 2392, localhost, executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:170)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:97)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:108)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:164)\r\n\t... 14 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:170)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:97)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:108)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:164)\r\n\t... 14 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-748716519ae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[0mitems\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36mrunJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# SparkContext#runJob.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 96.0 failed 1 times, most recent failure: Lost task 0.0 in stage 96.0 (TID 2392, localhost, executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:170)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:97)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:108)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:164)\r\n\t... 14 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:170)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:97)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:108)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:164)\r\n\t... 14 more\r\n"
     ]
    }
   ],
   "source": [
    "dat.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.toPandas().to_csv('/home/aaron/BigData135/135-project/model_df.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
